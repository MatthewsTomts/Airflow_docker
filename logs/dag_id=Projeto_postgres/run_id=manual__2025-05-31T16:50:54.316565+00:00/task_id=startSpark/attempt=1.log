{"timestamp":"2025-05-31T16:50:54.820199","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-05-31T16:50:54.820894","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/projeto1/projeto1.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-05-31T16:50:55.196808Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-31T16:50:56.467918Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-31T16:50:56.468420Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-31T16:50:56.468603Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-31T16:50:57.145611Z","level":"error","event":"25/05/31 16:50:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132003Z","level":"info","event":"+----+------+-------+-----------------+----------+","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132187Z","level":"info","event":"|  ID|  Name|    Age|            Email|  JoinDate|","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132262Z","level":"info","event":"+----+------+-------+-----------------+----------+","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132340Z","level":"info","event":"|   0|  NULL|     52|   grace@mail.com|2023-05-11|","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132431Z","level":"info","event":"|ID_1|   Ian|unknown|     bob@mail.com|2022-06-18|","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132513Z","level":"info","event":"|   2|  Dana|     41|grace@example.com|2020-01-17|","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132574Z","level":"info","event":"|   3| Frank|     38| charlie@test.org|2022-07-24|","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132632Z","level":"info","event":"|   4|Hannah|     57|     eli@mail.com|2022-05-30|","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132696Z","level":"info","event":"+----+------+-------+-----------------+----------+","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.132755Z","level":"info","event":"only showing top 5 rows","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.134166Z","level":"info","event":"root","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.134335Z","level":"info","event":" |-- ID: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.134401Z","level":"info","event":" |-- Name: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.134465Z","level":"info","event":" |-- Age: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.134530Z","level":"info","event":" |-- Email: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.134596Z","level":"info","event":" |-- JoinDate: string (nullable = true)","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.134660Z","level":"info","event":"","chan":"stdout","logger":"task"}
{"timestamp":"2025-05-31T16:51:03.134791","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
